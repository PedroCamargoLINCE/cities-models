{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4002118f",
   "metadata": {},
   "source": [
    "# Batch XGBoost Training for All Municipalities\n",
    "\n",
    "This notebook trains an XGBoost model for every municipality in the dataset using the best hyperparameters found for São Paulo. Results (predictions and metrics) are saved in an organized structure for further analysis or reruns on other time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4040fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from src.preprocessing import load_city_data, filter_city, clean_timeseries, prepare_data_for_model\n",
    "from src.train import evaluate_model, save_predictions, save_metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Set the best parameters found for São Paulo ---\n",
    "xgb_best_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'gamma': 0,\n",
    "    'min_child_weight': 1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# --- Data and output paths ---\n",
    "data_path = '../data/df_base_morb_resp.csv'\n",
    "results_dir = '../results/xgboost_batch_all_municipalities'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# --- Load all city codes ---\n",
    "df = load_city_data(data_path)\n",
    "city_codes = sorted(df['CD_MUN'].unique())\n",
    "\n",
    "# --- Model parameters ---\n",
    "model_params = {\n",
    "    'sequence_length': 8,\n",
    "    'forecast_horizon': 4,\n",
    "    'normalization': None,\n",
    "    'val_size': None\n",
    "}\n",
    "target_column = 'target'\n",
    "\n",
    "# --- Batch training ---\n",
    "for cd_mun in tqdm(city_codes, desc='Municipalities'):\n",
    "    city_name = str(cd_mun)\n",
    "    df_city = filter_city(df, cd_mun=cd_mun)\n",
    "    df_city = clean_timeseries(df_city, target_column=target_column)\n",
    "    data_dict = prepare_data_for_model(\n",
    "        df=df_city,\n",
    "        target_column=target_column,\n",
    "        sequence_length=model_params['sequence_length'],\n",
    "        forecast_horizon=model_params['forecast_horizon'],\n",
    "        normalization=model_params['normalization'],\n",
    "        val_size=model_params.get('val_size', None)\n",
    "    )\n",
    "    X_train = data_dict['X_train']\n",
    "    y_train = data_dict['y_train']\n",
    "    X_test = data_dict['X_test']\n",
    "    y_test = data_dict['y_test']\n",
    "    test_df = data_dict['test_df']\n",
    "    # Flatten for XGBoost\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "    # Train and predict\n",
    "    xgb = XGBRegressor(**xgb_best_params)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    # Save predictions and metrics\n",
    "    test_dates = test_df['week'].values[-len(y_test):] if 'week' in test_df.columns else np.arange(len(y_test))\n",
    "    preds_file = save_predictions(\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred,\n",
    "        dates=test_dates,\n",
    "        city_name=city_name,\n",
    "        model_name='xgboost',\n",
    "        output_dir=results_dir\n",
    "    )\n",
    "    metrics = evaluate_model(xgb, X_test, y_test)\n",
    "    metrics_file = save_metrics(\n",
    "        metrics=metrics,\n",
    "        city_name=city_name,\n",
    "        model_name='xgboost',\n",
    "        output_dir=results_dir,\n",
    "        params=model_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162e0be5",
   "metadata": {},
   "source": [
    "All predictions and metrics are saved in the results/xgboost_batch_all_municipalities directory, one file per city. You can rerun this notebook for other time series by changing the data path and parameters."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
