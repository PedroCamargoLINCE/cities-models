{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12e33a57",
   "metadata": {},
   "source": [
    "# Batch Deep Learning Training for All Brazilian State Capitals (Stacked GRU)\n",
    "\n",
    "This notebook trains the best deep learning model configuration (Stacked GRU, as determined in previous experiments) for each Brazilian state capital. Results are saved in a structured way for further analysis and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e153489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.preprocessing import load_city_data, filter_city, clean_timeseries, prepare_data_for_model\n",
    "from src.models import build_stacked_gru  # Use the best model function as determined\n",
    "from src.train import train_model, evaluate_model, save_predictions, save_metrics\n",
    "from src.utils import plot_training_history\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- List of state capitals and their IBGE codes ---\n",
    "capitals = [\n",
    "    (\"Rio Branco\", 1200401), (\"Maceió\", 2704302), (\"Macapá\", 1600303), (\"Manaus\", 1302603),\n",
    "    (\"Salvador\", 2927408), (\"Fortaleza\", 2304400), (\"Brasília\", 5300108), (\"Vitória\", 3205309),\n",
    "    (\"Goiânia\", 5208707), (\"São Luís\", 2111300), (\"Cuiabá\", 5103403), (\"Campo Grande\", 5002704),\n",
    "    (\"Belo Horizonte\", 3106200), (\"Belém\", 1501402), (\"João Pessoa\", 2507507), (\"Curitiba\", 4106902),\n",
    "    (\"Recife\", 2611606), (\"Teresina\", 2211001), (\"Rio de Janeiro\", 3304557), (\"Natal\", 2408102),\n",
    "    (\"Porto Alegre\", 4314902), (\"Porto Velho\", 1100205), (\"Boa Vista\", 1400100), (\"Florianópolis\", 4205407),\n",
    "    (\"São Paulo\", 3550308), (\"Aracaju\", 2800308), (\"Palmas\", 1721000)\n",
    "]\n",
    "\n",
    "# --- Model and data parameters (update as needed) ---\n",
    "model_params = {\n",
    "    'sequence_length': 12,\n",
    "    'forecast_horizon': 4,\n",
    "    'normalization': 'zscore',\n",
    "    'val_size': 12\n",
    "}\n",
    "target_column = 'target'\n",
    "results_dir = '../results/dl_batch_state_capitals'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# --- Load data ---\n",
    "data_path = '../data/df_base_morb_resp.csv'\n",
    "df = load_city_data(data_path)\n",
    "\n",
    "# --- Batch training ---\n",
    "for city_name, cd_mun in tqdm(capitals, desc='State Capitals'):\n",
    "    df_city = filter_city(df, cd_mun=cd_mun)\n",
    "    df_city = clean_timeseries(df_city, target_column=target_column)\n",
    "    data_dict = prepare_data_for_model(\n",
    "        df=df_city,\n",
    "        target_column=target_column,\n",
    "        sequence_length=model_params['sequence_length'],\n",
    "        forecast_horizon=model_params['forecast_horizon'],\n",
    "        normalization=model_params['normalization'],\n",
    "        val_size=model_params.get('val_size', None)\n",
    "    )\n",
    "    X_train = data_dict['X_train']\n",
    "    y_train = data_dict['y_train']\n",
    "    X_val = data_dict.get('X_val', None)\n",
    "    y_val = data_dict.get('y_val', None)\n",
    "    X_test = data_dict['X_test']\n",
    "    y_test = data_dict['y_test']\n",
    "    test_df = data_dict['test_df']\n",
    "    scaler = data_dict.get('scaler')\n",
    "    # Build and train model\n",
    "    input_shape = X_train.shape[1:]\n",
    "    model = build_stacked_gru(input_shape=input_shape, loss='huber')\n",
    "    history = train_model(\n",
    "        model=model,\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_val=X_val,\n",
    "        y_val=y_val,\n",
    "        batch_size=32,\n",
    "        epochs=100,\n",
    "        patience=10,\n",
    "        verbose=0\n",
    "    )\n",
    "    # Evaluate and save\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_dates = test_df['week'].values[-len(y_test):] if 'week' in test_df.columns else np.arange(len(y_test))\n",
    "    preds_file = save_predictions(\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred,\n",
    "        dates=test_dates,\n",
    "        city_name=city_name,\n",
    "        model_name='gru_stacked',\n",
    "        output_dir=results_dir\n",
    "    )\n",
    "    metrics = evaluate_model(model, X_test, y_test, scaler=scaler)\n",
    "    metrics_file = save_metrics(\n",
    "        metrics=metrics,\n",
    "        city_name=city_name,\n",
    "        model_name='gru_stacked',\n",
    "        output_dir=results_dir,\n",
    "        params=model_params\n",
    "    )\n",
    "    # Optionally, save training history plot\n",
    "    if history is not None:\n",
    "        fig = plot_training_history(history)\n",
    "        fig.savefig(os.path.join(results_dir, f'{city_name}_gru_stacked_training_history.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f68bcef",
   "metadata": {},
   "source": [
    "All predictions, metrics, and training history plots are saved in the results/dl_batch_state_capitals directory, one file per capital. You can rerun this notebook for other targets or model configs as needed."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
