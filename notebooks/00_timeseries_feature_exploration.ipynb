{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8189a79f",
   "metadata": {},
   "source": [
    "# Time Series & Feature Exploration Notebook\n",
    "\n",
    "This notebook provides a comprehensive toolkit for exploring, visualizing, and diagnosing time series and features in the respiratory morbidity dataset. You can select a specific city (by IBGE code) or analyze the sum across all cities (countrywise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9add22a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, acf, pacf\n",
    "from scipy.stats import boxcox, zscore, skew, kurtosis, entropy\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "from dateutil import parser\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For interactive widgets (city selection, etc.)\n",
    "try:\n",
    "    from ipywidgets import interact, widgets\n",
    "except ImportError:\n",
    "    interact = None\n",
    "    widgets = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5815331",
   "metadata": {},
   "source": [
    "## 1. Data Loading & City Selection\n",
    "- Load the main dataset.\n",
    "- Allow user to select a city (by IBGE code) or \"All\" for countrywise sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e06f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "DATA_PATH = '../data/df_base_morb_resp.csv'\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=['week'])\n",
    "\n",
    "# List of available cities\n",
    "city_codes = df['CD_MUN'].unique()\n",
    "city_options = ['All'] + sorted(city_codes.tolist())\n",
    "\n",
    "# Widget for city selection (if available)\n",
    "def select_city(city_code='All'):\n",
    "    if city_code == 'All':\n",
    "        df_sel = df.groupby('week').agg({col: 'sum' if df[col].dtype != 'O' else 'first' for col in df.columns if col != 'week'}).reset_index()\n",
    "        label = 'All Cities (Sum)'\n",
    "    else:\n",
    "        df_sel = df[df['CD_MUN'] == int(city_code)].copy()\n",
    "        label = f'City {city_code}'\n",
    "    return df_sel, label\n",
    "\n",
    "if interact:\n",
    "    city_widget = widgets.Dropdown(options=city_options, value='All', description='City:')\n",
    "    display(city_widget)\n",
    "    city_code = city_widget.value\n",
    "else:\n",
    "    city_code = 'All'\n",
    "df_city, city_label = select_city(city_code)\n",
    "print(f\"Selected: {city_label}, shape: {df_city.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d2f253",
   "metadata": {},
   "source": [
    "## 2. Basic Structure & Summary\n",
    "- Missing values, duplicates, gaps, summary stats, raw plot, resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a98a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "missing = df_city.isnull().sum()\n",
    "missing_pct = df_city.isnull().mean() * 100\n",
    "print('Missing values (count):\\n', missing)\n",
    "print('Missing values (%):\\n', missing_pct)\n",
    "\n",
    "# Duplicates\n",
    "duplicates = df_city.duplicated(subset=['week']).sum()\n",
    "print(f\"Duplicate timestamps: {duplicates}\")\n",
    "\n",
    "# Gaps in time\n",
    "df_city = df_city.sort_values('week')\n",
    "all_weeks = pd.date_range(df_city['week'].min(), df_city['week'].max(), freq='W')\n",
    "gaps = set(all_weeks) - set(df_city['week'])\n",
    "print(f\"Number of missing weeks: {len(gaps)}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(df_city.describe())\n",
    "\n",
    "# Raw time series plot\n",
    "target_col = 'target' if 'target' in df_city.columns else df_city.columns[-1]\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(df_city['week'], df_city[target_col], marker='o')\n",
    "plt.title(f\"{city_label} - Raw Time Series ({target_col})\")\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel(target_col)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Resample to monthly (if weekly)\n",
    "df_month = df_city.set_index('week').resample('M')[target_col].sum()\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(df_month.index, df_month.values, marker='o', color='tab:orange')\n",
    "plt.title(f\"{city_label} - Monthly Resampled ({target_col})\")\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel(target_col)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ddadde",
   "metadata": {},
   "source": [
    "## 3. Stationarity & Trend Analysis\n",
    "- STL decomposition, rolling stats, ADF/KPSS, differencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0926f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STL decomposition\n",
    "stl = STL(df_city[target_col], period=52, robust=True)\n",
    "res = stl.fit()\n",
    "res.plot()\n",
    "plt.suptitle(f\"STL Decomposition - {city_label}\")\n",
    "plt.show()\n",
    "\n",
    "# Rolling mean & std\n",
    "window = 8\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(df_city['week'], df_city[target_col], label='Original')\n",
    "plt.plot(df_city['week'], df_city[target_col].rolling(window).mean(), label=f'Rolling Mean ({window})')\n",
    "plt.plot(df_city['week'], df_city[target_col].rolling(window).std(), label=f'Rolling Std ({window})')\n",
    "plt.legend()\n",
    "plt.title(f\"Rolling Statistics - {city_label}\")\n",
    "plt.show()\n",
    "\n",
    "# Dickey-Fuller test\n",
    "adf_result = adfuller(df_city[target_col].dropna())\n",
    "print('ADF Statistic:', adf_result[0])\n",
    "print('p-value:', adf_result[1])\n",
    "\n",
    "# KPSS test\n",
    "try:\n",
    "    kpss_result = kpss(df_city[target_col].dropna(), regression='c')\n",
    "    print('KPSS Statistic:', kpss_result[0])\n",
    "    print('p-value:', kpss_result[1])\n",
    "except Exception as e:\n",
    "    print('KPSS test failed:', e)\n",
    "\n",
    "# First/second differences\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(df_city['week'], df_city[target_col].diff(), label='1st Diff')\n",
    "plt.plot(df_city['week'], df_city[target_col].diff(2), label='2nd Diff')\n",
    "plt.legend()\n",
    "plt.title(f\"First/Second Differences - {city_label}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b467e",
   "metadata": {},
   "source": [
    "## 4. Seasonality & Cyclic Patterns\n",
    "- Seasonal plots, ACF/PACF, periodogram, STL/Fourier, heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14083b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal plot: average per week of year\n",
    "if 'week' in df_city.columns:\n",
    "    df_city['weekofyear'] = df_city['week'].dt.isocalendar().week\n",
    "    weekly_avg = df_city.groupby('weekofyear')[target_col].mean()\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(weekly_avg.index, weekly_avg.values)\n",
    "    plt.title(f\"Average per Week of Year - {city_label}\")\n",
    "    plt.xlabel('Week of Year')\n",
    "    plt.ylabel(target_col)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# ACF/PACF\n",
    "lags = min(52, len(df_city)-1)\n",
    "fig, ax = plt.subplots(2,1,figsize=(12,6))\n",
    "acf_vals = acf(df_city[target_col].dropna(), nlags=lags)\n",
    "pacf_vals = pacf(df_city[target_col].dropna(), nlags=lags)\n",
    "ax[0].stem(range(len(acf_vals)), acf_vals, use_line_collection=True)\n",
    "ax[0].set_title('ACF')\n",
    "ax[1].stem(range(len(pacf_vals)), pacf_vals, use_line_collection=True)\n",
    "ax[1].set_title('PACF')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Periodogram\n",
    "from scipy.signal import periodogram\n",
    "freqs, power = periodogram(df_city[target_col].dropna())\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(freqs, power)\n",
    "plt.title('Periodogram')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Power')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Heatmap: year vs week\n",
    "if 'week' in df_city.columns:\n",
    "    df_city['year'] = df_city['week'].dt.year\n",
    "    df_city['weekofyear'] = df_city['week'].dt.isocalendar().week\n",
    "    pivot = df_city.pivot_table(index='year', columns='weekofyear', values=target_col, aggfunc='mean')\n",
    "    plt.figure(figsize=(16,6))\n",
    "    sns.heatmap(pivot, cmap='coolwarm', annot=False)\n",
    "    plt.title('Heatmap: Value by Year/Week')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1510b410",
   "metadata": {},
   "source": [
    "## 5. Outlier & Anomaly Detection\n",
    "- Boxplots, z-score, visual spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7779b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot by month\n",
    "if 'week' in df_city.columns:\n",
    "    df_city['month'] = df_city['week'].dt.month\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.boxplot(x='month', y=target_col, data=df_city)\n",
    "    plt.title('Boxplot by Month')\n",
    "    plt.show()\n",
    "\n",
    "# Z-score outlier detection\n",
    "zs = zscore(df_city[target_col].dropna())\n",
    "outliers = np.where(np.abs(zs) > 3)[0]\n",
    "print(f\"Number of z-score outliers (>3 std): {len(outliers)}\")\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(df_city['week'], df_city[target_col], label='Value')\n",
    "plt.scatter(df_city['week'].iloc[outliers], df_city[target_col].iloc[outliers], color='red', label='Outlier')\n",
    "plt.legend()\n",
    "plt.title('Outlier Detection (Z-score)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e95476c",
   "metadata": {},
   "source": [
    "## 6. Distribution & Transformation\n",
    "- Histogram, KDE, log/Box-Cox, skewness, kurtosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd8811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram & KDE\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df_city[target_col].dropna(), kde=True, bins=30)\n",
    "plt.title('Histogram & KDE')\n",
    "plt.show()\n",
    "\n",
    "# Log transform\n",
    "plt.figure(figsize=(10,5))\n",
    "log_vals = np.log1p(df_city[target_col].dropna())\n",
    "sns.histplot(log_vals, kde=True, bins=30)\n",
    "plt.title('Log-Transformed Histogram')\n",
    "plt.show()\n",
    "\n",
    "# Box-Cox (only positive values)\n",
    "if (df_city[target_col] > 0).all():\n",
    "    bc_vals, bc_lambda = boxcox(df_city[target_col].dropna())\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.histplot(bc_vals, kde=True, bins=30)\n",
    "    plt.title(f'Box-Cox Transformed (lambda={bc_lambda:.2f})')\n",
    "    plt.show()\n",
    "\n",
    "# Skewness & kurtosis\n",
    "print('Skewness:', skew(df_city[target_col].dropna()))\n",
    "print('Kurtosis:', kurtosis(df_city[target_col].dropna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf88501a",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering Insights\n",
    "- Lag correlation, exogenous features, date features, value by category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b955af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag feature correlation\n",
    "max_lag = 12\n",
    "corrs = [df_city[target_col].autocorr(lag) for lag in range(1, max_lag+1)]\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(range(1, max_lag+1), corrs)\n",
    "plt.title('Lag Feature Correlation')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.show()\n",
    "\n",
    "# Correlation with exogenous features (if present)\n",
    "exog_cols = [col for col in df_city.columns if col not in ['week', 'CD_MUN', target_col]]\n",
    "if exog_cols:\n",
    "    corr_matrix = df_city[[target_col] + exog_cols].corr()\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "    plt.title('Correlation with Exogenous Features')\n",
    "    plt.show()\n",
    "\n",
    "# Date-based features\n",
    "if 'week' in df_city.columns:\n",
    "    df_city['weekofyear'] = df_city['week'].dt.isocalendar().week\n",
    "    df_city['month'] = df_city['week'].dt.month\n",
    "    df_city['quarter'] = df_city['week'].dt.quarter\n",
    "    df_city['year'] = df_city['week'].dt.year\n",
    "    # Value by season\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.boxplot(x='quarter', y=target_col, data=df_city)\n",
    "    plt.title('Value by Quarter')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9456f50b",
   "metadata": {},
   "source": [
    "## 8. Forecastability & Complexity\n",
    "- CV, entropy, naive baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed44cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficient of Variation\n",
    "cv = df_city[target_col].std() / df_city[target_col].mean()\n",
    "print(f\"Coefficient of Variation (CV): {cv:.3f}\")\n",
    "\n",
    "# Entropy (discretized)\n",
    "vals = pd.cut(df_city[target_col].dropna(), bins=20, labels=False)\n",
    "ent = entropy(np.bincount(vals))\n",
    "print(f\"Entropy (discretized): {ent:.3f}\")\n",
    "\n",
    "# Naive baseline (last value)\n",
    "y_true = df_city[target_col].values[1:]\n",
    "y_pred = df_city[target_col].values[:-1]\n",
    "mae = np.mean(np.abs(y_true - y_pred))\n",
    "print(f\"Naive Last Value MAE: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2474dbe6",
   "metadata": {},
   "source": [
    "## 9. Domain-Specific Checks\n",
    "- Health policy events, cumulative/incidence, reporting gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a2a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: COVID onset vertical line\n",
    "covid_start = pd.to_datetime('2020-03-01')\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(df_city['week'], df_city[target_col], label='Value')\n",
    "plt.axvline(covid_start, color='red', linestyle='--', label='COVID Onset')\n",
    "plt.title('Time Series with COVID Onset')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Check if target is cumulative (monotonic)\n",
    "if (df_city[target_col].diff().dropna() >= 0).all():\n",
    "    print('Target appears cumulative (monotonic increase)')\n",
    "else:\n",
    "    print('Target is not cumulative')\n",
    "\n",
    "# Reporting delays: check for long gaps\n",
    "week_diffs = df_city['week'].sort_values().diff().dt.days.dropna()\n",
    "long_gaps = week_diffs[week_diffs > 14]\n",
    "if not long_gaps.empty:\n",
    "    print(f\"Long reporting gaps (>{14} days):\\n\", long_gaps)\n",
    "else:\n",
    "    print('No long reporting gaps detected')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6465b0a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook is modular and can be extended for new datasets or additional feature/target columns. Use the widgets or change the city code to explore different locations or the country as a whole."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
