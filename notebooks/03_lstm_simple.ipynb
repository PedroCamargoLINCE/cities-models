{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e050c12",
   "metadata": {},
   "source": [
    "# LSTM Simples (Previsão da Soma das Próximas 4 Semanas)\n",
    "\n",
    "Este notebook implementa o modelo LSTM simples para previsão da **soma das próximas 4 semanas** (previsão mensal) das taxas de morbidade respiratória em municípios brasileiros.\n",
    "\n",
    "- **Modelo:** LSTM Simples\n",
    "- **Alvo:** Soma das próximas 4 semanas (previsão mensal)\n",
    "- **Input:** sequência de 12 semanas (shape: [batch, 12, 1])\n",
    "- **Arquitetura:** LSTM(32, return_sequences=False) → Dense(1)\n",
    "- **Perda:** MAE\n",
    "- **Todo o código é modular e importado dos módulos `src/`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c411100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\pedro\\OneDrive - Unesp\\Documentos\\GitHub\\cities-models\\cities-models\n",
      "Added c:\\Users\\pedro\\OneDrive - Unesp\\Documentos\\GitHub\\cities-models\\cities-models to sys.path\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Add the project root to sys.path (not the src directory)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"Added {project_root} to sys.path\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from src.preprocessing import load_city_data, prepare_data_for_model, filter_city, clean_timeseries\n",
    "from src.models import build_lstm\n",
    "from src.train import train_model, evaluate_model, generate_forecasts, save_predictions, save_metrics\n",
    "from src.utils import plot_forecast, plot_forecast_error, plot_training_history\n",
    "\n",
    "results_dir = os.path.join('results', 'morbcirc_run', 'lstm_simple')\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c866c96",
   "metadata": {},
   "source": [
    "## Estrutura do Repositório\n",
    "\n",
    "- **data/**: Um CSV por cidade, cada um com coluna de data, coluna alvo e features opcionais.\n",
    "- **notebooks/**: Notebooks para cada experimento. Apenas visualização e exploração.\n",
    "- **src/**: Módulos reutilizáveis:\n",
    "    - `preprocessing.py`: Carregamento, normalização, split, criação de janelas\n",
    "    - `models.py`: Definições de modelos (baselines, MLP, LSTM, etc.)\n",
    "    - `train.py`: Rotinas de treino e avaliação\n",
    "    - `utils.py`: Funções auxiliares (plot, métricas, etc.)\n",
    "- **results/**: Previsões e métricas salvas.\n",
    "- **instructions.md**: Guia de boas práticas.\n",
    "\n",
    "**Toda a lógica central está em `src/`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63adfea",
   "metadata": {},
   "source": [
    "## Carregamento e Exploração dos Dados\n",
    "\n",
    "Carregue os dados de morbidade respiratória para análise. Você pode iterar sobre todas as cidades ou selecionar uma específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d62584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato do dataset: (6344064, 11)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CD_MUN",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "target",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "week",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PIB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DENS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "URB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CO2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CH4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "N2O",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LAT",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LON",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "cda021d1-9364-4cd3-9a09-e194f00e05ed",
       "rows": [
        [
         "0",
         "1100015",
         "0.1998722995419647",
         "1",
         "3469.14",
         "3.541042988352913",
         "0.000610513",
         "550.985905310587",
         "92.946598",
         "6.657746720369675",
         "-12.88321252820032",
         "-62.39"
        ],
        [
         "1",
         "1100015",
         "1.3041841087884944",
         "2",
         "3469.14",
         "3.541042988352913",
         "0.000610513",
         "550.985905310587",
         "92.946598",
         "6.657746720369675",
         "-12.88321252820032",
         "-62.39"
        ],
        [
         "2",
         "1100015",
         "2.495193532395542",
         "3",
         "3469.14",
         "3.541042988352913",
         "0.000610513",
         "550.985905310587",
         "92.946598",
         "6.657746720369675",
         "-12.88321252820032",
         "-62.39"
        ],
        [
         "3",
         "1100015",
         "3.538533059273999",
         "4",
         "3469.14",
         "3.541042988352913",
         "0.000610513",
         "550.985905310587",
         "92.946598",
         "6.657746720369675",
         "-12.88321252820032",
         "-62.39"
        ],
        [
         "4",
         "1100015",
         "11.92722447819399",
         "5",
         "3469.14",
         "3.541042988352913",
         "0.000610513",
         "550.985905310587",
         "92.946598",
         "6.657746720369675",
         "-12.88321252820032",
         "-62.39"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD_MUN</th>\n",
       "      <th>target</th>\n",
       "      <th>week</th>\n",
       "      <th>PIB</th>\n",
       "      <th>DENS</th>\n",
       "      <th>URB</th>\n",
       "      <th>CO2</th>\n",
       "      <th>CH4</th>\n",
       "      <th>N2O</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100015</td>\n",
       "      <td>0.199872</td>\n",
       "      <td>1</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1100015</td>\n",
       "      <td>1.304184</td>\n",
       "      <td>2</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100015</td>\n",
       "      <td>2.495194</td>\n",
       "      <td>3</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100015</td>\n",
       "      <td>3.538533</td>\n",
       "      <td>4</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100015</td>\n",
       "      <td>11.927224</td>\n",
       "      <td>5</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CD_MUN     target  week      PIB      DENS       URB         CO2  \\\n",
       "0  1100015   0.199872     1  3469.14  3.541043  0.000611  550.985905   \n",
       "1  1100015   1.304184     2  3469.14  3.541043  0.000611  550.985905   \n",
       "2  1100015   2.495194     3  3469.14  3.541043  0.000611  550.985905   \n",
       "3  1100015   3.538533     4  3469.14  3.541043  0.000611  550.985905   \n",
       "4  1100015  11.927224     5  3469.14  3.541043  0.000611  550.985905   \n",
       "\n",
       "         CH4       N2O        LAT    LON  \n",
       "0  92.946598  6.657747 -12.883213 -62.39  \n",
       "1  92.946598  6.657747 -12.883213 -62.39  \n",
       "2  92.946598  6.657747 -12.883213 -62.39  \n",
       "3  92.946598  6.657747 -12.883213 -62.39  \n",
       "4  92.946598  6.657747 -12.883213 -62.39  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo: Carregar dados de uma cidade (ajuste o caminho conforme necessário)\n",
    "data_path = '../data/df_base_morb_circ.csv'\n",
    "df = load_city_data(data_path)\n",
    "\n",
    "print(f\"Formato do dataset: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8565360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas disponíveis:\n",
      "['CD_MUN', 'target', 'week', 'PIB', 'DENS', 'URB', 'CO2', 'CH4', 'N2O', 'LAT', 'LON']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas disponíveis:\n",
      "['CD_MUN', 'target', 'week', 'PIB', 'DENS', 'URB', 'CO2', 'CH4', 'N2O', 'LAT', 'LON']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "CD_MUN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "week",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PIB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DENS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "URB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CO2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CH4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "N2O",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LAT",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LON",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "bf539fc1-d320-493c-8068-c0343e714a2c",
       "rows": [
        [
         "count",
         "6344064.0",
         "6344064.0",
         "6344064.0",
         "5726592.0",
         "5726592.0",
         "5726592.0",
         "5726592.0",
         "5726592.0",
         "5726592.0",
         "5726592.0",
         "5726592.0"
        ],
        [
         "mean",
         "3241649.6711458145",
         "14.660499158980118",
         "576.5",
         "3567.273876064509",
         "69.38193623641683",
         "0.009914410149087572",
         "27641.11717415683",
         "597.1644896948127",
         "9.700125300720998",
         "-16.33024055312225",
         "-46.322342587004606"
        ],
        [
         "std",
         "979687.4618398991",
         "14.137207752706646",
         "332.553655970003",
         "3776.04625877588",
         "343.36045112676254",
         "0.040767575201603234",
         "95698.33901922603",
         "10303.286456507956",
         "68.01206097276895",
         "8.33319050097618",
         "6.413752347262668"
        ],
        [
         "min",
         "1100015.0",
         "0.0",
         "1.0",
         "625.09",
         "0.0892396497852368",
         "7.13181e-07",
         "0.0",
         "0.0",
         "0.0",
         "-33.6525367692393",
         "-73.484"
        ],
        [
         "25%",
         "2511202.0",
         "5.462075712531106",
         "288.75",
         "1482.63",
         "10.60285947513215",
         "0.000928566",
         "3303.8755322458032",
         "57.406686",
         "3.77021653062718",
         "-22.74836785088451",
         "-50.908"
        ],
        [
         "50%",
         "3144672.0",
         "11.588715141393088",
         "576.5",
         "2745.46",
         "22.50040243622204",
         "0.00214708",
         "7940.410066440945",
         "110.007816",
         "6.881932248735743",
         "-17.80183233831485",
         "-46.519"
        ],
        [
         "75%",
         "4116604.0",
         "20.15466034284312",
         "864.25",
         "4477.39",
         "44.06899085925944",
         "0.005144121",
         "18026.5870942235",
         "187.571528",
         "10.231718771952178",
         "-8.379808421554571",
         "-41.599"
        ],
        [
         "max",
         "5300108.0",
         "2106.9440103540205",
         "1152.0",
         "122011.2",
         "12763.56193100596",
         "0.960127697",
         "2074703.1606327249",
         "481882.219992",
         "3683.564874587295",
         "4.685424949943297",
         "-34.87"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD_MUN</th>\n",
       "      <th>target</th>\n",
       "      <th>week</th>\n",
       "      <th>PIB</th>\n",
       "      <th>DENS</th>\n",
       "      <th>URB</th>\n",
       "      <th>CO2</th>\n",
       "      <th>CH4</th>\n",
       "      <th>N2O</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.344064e+06</td>\n",
       "      <td>6.344064e+06</td>\n",
       "      <td>6.344064e+06</td>\n",
       "      <td>5.726592e+06</td>\n",
       "      <td>5.726592e+06</td>\n",
       "      <td>5.726592e+06</td>\n",
       "      <td>5.726592e+06</td>\n",
       "      <td>5.726592e+06</td>\n",
       "      <td>5.726592e+06</td>\n",
       "      <td>5.726592e+06</td>\n",
       "      <td>5.726592e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.241650e+06</td>\n",
       "      <td>1.466050e+01</td>\n",
       "      <td>5.765000e+02</td>\n",
       "      <td>3.567274e+03</td>\n",
       "      <td>6.938194e+01</td>\n",
       "      <td>9.914410e-03</td>\n",
       "      <td>2.764112e+04</td>\n",
       "      <td>5.971645e+02</td>\n",
       "      <td>9.700125e+00</td>\n",
       "      <td>-1.633024e+01</td>\n",
       "      <td>-4.632234e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.796875e+05</td>\n",
       "      <td>1.413721e+01</td>\n",
       "      <td>3.325537e+02</td>\n",
       "      <td>3.776046e+03</td>\n",
       "      <td>3.433605e+02</td>\n",
       "      <td>4.076758e-02</td>\n",
       "      <td>9.569834e+04</td>\n",
       "      <td>1.030329e+04</td>\n",
       "      <td>6.801206e+01</td>\n",
       "      <td>8.333191e+00</td>\n",
       "      <td>6.413752e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.100015e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.250900e+02</td>\n",
       "      <td>8.923965e-02</td>\n",
       "      <td>7.131810e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.365254e+01</td>\n",
       "      <td>-7.348400e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.511202e+06</td>\n",
       "      <td>5.462076e+00</td>\n",
       "      <td>2.887500e+02</td>\n",
       "      <td>1.482630e+03</td>\n",
       "      <td>1.060286e+01</td>\n",
       "      <td>9.285660e-04</td>\n",
       "      <td>3.303876e+03</td>\n",
       "      <td>5.740669e+01</td>\n",
       "      <td>3.770217e+00</td>\n",
       "      <td>-2.274837e+01</td>\n",
       "      <td>-5.090800e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.144672e+06</td>\n",
       "      <td>1.158872e+01</td>\n",
       "      <td>5.765000e+02</td>\n",
       "      <td>2.745460e+03</td>\n",
       "      <td>2.250040e+01</td>\n",
       "      <td>2.147080e-03</td>\n",
       "      <td>7.940410e+03</td>\n",
       "      <td>1.100078e+02</td>\n",
       "      <td>6.881932e+00</td>\n",
       "      <td>-1.780183e+01</td>\n",
       "      <td>-4.651900e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.116604e+06</td>\n",
       "      <td>2.015466e+01</td>\n",
       "      <td>8.642500e+02</td>\n",
       "      <td>4.477390e+03</td>\n",
       "      <td>4.406899e+01</td>\n",
       "      <td>5.144121e-03</td>\n",
       "      <td>1.802659e+04</td>\n",
       "      <td>1.875715e+02</td>\n",
       "      <td>1.023172e+01</td>\n",
       "      <td>-8.379808e+00</td>\n",
       "      <td>-4.159900e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.300108e+06</td>\n",
       "      <td>2.106944e+03</td>\n",
       "      <td>1.152000e+03</td>\n",
       "      <td>1.220112e+05</td>\n",
       "      <td>1.276356e+04</td>\n",
       "      <td>9.601277e-01</td>\n",
       "      <td>2.074703e+06</td>\n",
       "      <td>4.818822e+05</td>\n",
       "      <td>3.683565e+03</td>\n",
       "      <td>4.685425e+00</td>\n",
       "      <td>-3.487000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CD_MUN        target          week           PIB          DENS  \\\n",
       "count  6.344064e+06  6.344064e+06  6.344064e+06  5.726592e+06  5.726592e+06   \n",
       "mean   3.241650e+06  1.466050e+01  5.765000e+02  3.567274e+03  6.938194e+01   \n",
       "std    9.796875e+05  1.413721e+01  3.325537e+02  3.776046e+03  3.433605e+02   \n",
       "min    1.100015e+06  0.000000e+00  1.000000e+00  6.250900e+02  8.923965e-02   \n",
       "25%    2.511202e+06  5.462076e+00  2.887500e+02  1.482630e+03  1.060286e+01   \n",
       "50%    3.144672e+06  1.158872e+01  5.765000e+02  2.745460e+03  2.250040e+01   \n",
       "75%    4.116604e+06  2.015466e+01  8.642500e+02  4.477390e+03  4.406899e+01   \n",
       "max    5.300108e+06  2.106944e+03  1.152000e+03  1.220112e+05  1.276356e+04   \n",
       "\n",
       "                URB           CO2           CH4           N2O           LAT  \\\n",
       "count  5.726592e+06  5.726592e+06  5.726592e+06  5.726592e+06  5.726592e+06   \n",
       "mean   9.914410e-03  2.764112e+04  5.971645e+02  9.700125e+00 -1.633024e+01   \n",
       "std    4.076758e-02  9.569834e+04  1.030329e+04  6.801206e+01  8.333191e+00   \n",
       "min    7.131810e-07  0.000000e+00  0.000000e+00  0.000000e+00 -3.365254e+01   \n",
       "25%    9.285660e-04  3.303876e+03  5.740669e+01  3.770217e+00 -2.274837e+01   \n",
       "50%    2.147080e-03  7.940410e+03  1.100078e+02  6.881932e+00 -1.780183e+01   \n",
       "75%    5.144121e-03  1.802659e+04  1.875715e+02  1.023172e+01 -8.379808e+00   \n",
       "max    9.601277e-01  2.074703e+06  4.818822e+05  3.683565e+03  4.685425e+00   \n",
       "\n",
       "                LON  \n",
       "count  5.726592e+06  \n",
       "mean  -4.632234e+01  \n",
       "std    6.413752e+00  \n",
       "min   -7.348400e+01  \n",
       "25%   -5.090800e+01  \n",
       "50%   -4.651900e+01  \n",
       "75%   -4.159900e+01  \n",
       "max   -3.487000e+01  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Colunas disponíveis:\")\n",
    "print(df.columns.tolist())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2910e9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected city shape: (1152, 11)\n"
     ]
    }
   ],
   "source": [
    "# Select city for modeling (set to None to use all cities)\n",
    "CD_MUN_SELECTED = 3550308  # São Paulo\n",
    "\n",
    "df_city = filter_city(df, cd_mun=CD_MUN_SELECTED)\n",
    "df_city = clean_timeseries(df_city, target_column='target')\n",
    "print(f\"Selected city shape: {df_city.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407ce37",
   "metadata": {},
   "source": [
    "## Pré-processamento\n",
    "\n",
    "Prepare os dados para o modelo LSTM simples. O input é uma sequência de 12 semanas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c3b1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessamento para LSTM simples (soma das próximas 4 semanas)\n",
    "model_params = {\n",
    "    'sequence_length': 12,\n",
    "    'forecast_horizon': 4,  # Soma das próximas 4 semanas (previsão mensal)\n",
    "    'normalization': 'zscore',\n",
    "    'val_size': None  # Use default (10% of train)\n",
    "}\n",
    "\n",
    "target_column = 'target'\n",
    "\n",
    "data_dict = prepare_data_for_model(\n",
    "    df=df_city,\n",
    "    target_column=target_column,\n",
    "    sequence_length=model_params['sequence_length'],\n",
    "    forecast_horizon=model_params['forecast_horizon'],\n",
    "    normalization=model_params['normalization'],\n",
    "    val_size=model_params.get('val_size', None)\n",
    ")\n",
    "\n",
    "X_train = data_dict['X_train']\n",
    "y_train = data_dict['y_train']\n",
    "X_test = data_dict['X_test']\n",
    "y_test = data_dict['y_test']\n",
    "test_df = data_dict['test_df']\n",
    "scaler = data_dict.get('scaler')\n",
    "feature_columns = data_dict.get('feature_columns', None)\n",
    "\n",
    "# Garantir que não ocorre erro caso X_val/y_val não existam\n",
    "X_val = data_dict.get('X_val', None)\n",
    "y_val = data_dict.get('y_val', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2973137c",
   "metadata": {},
   "source": [
    "## Definição e Treinamento do Modelo\n",
    "\n",
    "O modelo LSTM simples utiliza uma camada LSTM com 32 unidades e uma camada densa de saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2a4ea89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.6986 - val_loss: 2.6523 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.6986 - val_loss: 2.6523 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0161 - val_loss: 2.1694 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0161 - val_loss: 2.1694 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6489 - val_loss: 2.0328 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6489 - val_loss: 2.0328 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5108 - val_loss: 1.9285 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5108 - val_loss: 1.9285 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4147 - val_loss: 1.9218 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4147 - val_loss: 1.9218 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4166 - val_loss: 1.8347 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4166 - val_loss: 1.8347 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3073 - val_loss: 1.8514 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3073 - val_loss: 1.8514 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3821 - val_loss: 1.8487 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3821 - val_loss: 1.8487 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3692 - val_loss: 1.7723 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3692 - val_loss: 1.7723 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3005 - val_loss: 1.7522 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3005 - val_loss: 1.7522 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3683 - val_loss: 1.6861 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3683 - val_loss: 1.6861 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1809 - val_loss: 1.6243 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1809 - val_loss: 1.6243 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2483 - val_loss: 1.5532 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2483 - val_loss: 1.5532 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2704 - val_loss: 1.5800 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2704 - val_loss: 1.5800 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2464 - val_loss: 1.5683 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2464 - val_loss: 1.5683 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1823 - val_loss: 1.5376 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1823 - val_loss: 1.5376 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2036 - val_loss: 1.5329 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2036 - val_loss: 1.5329 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1545 - val_loss: 1.5144 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1545 - val_loss: 1.5144 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1616 - val_loss: 1.4729 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1616 - val_loss: 1.4729 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0759 - val_loss: 1.4211 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0759 - val_loss: 1.4211 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1028 - val_loss: 1.4106 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1028 - val_loss: 1.4106 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0688 - val_loss: 1.4269 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0688 - val_loss: 1.4269 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0257 - val_loss: 1.3911 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0257 - val_loss: 1.3911 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0616 - val_loss: 1.3834 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0616 - val_loss: 1.3834 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9818 - val_loss: 1.3187 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9818 - val_loss: 1.3187 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0569 - val_loss: 1.2655 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0569 - val_loss: 1.2655 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0518 - val_loss: 1.3505 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0518 - val_loss: 1.3505 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0214 - val_loss: 1.2756 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0214 - val_loss: 1.2756 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9870 - val_loss: 1.2694 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9870 - val_loss: 1.2694 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9806 - val_loss: 1.3146 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9806 - val_loss: 1.3146 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9686 - val_loss: 1.3121 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9686 - val_loss: 1.3121 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9749 - val_loss: 1.2148 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9749 - val_loss: 1.2148 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9411 - val_loss: 1.2283 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9411 - val_loss: 1.2283 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9032 - val_loss: 1.2461 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9032 - val_loss: 1.2461 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8979 - val_loss: 1.2237 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8979 - val_loss: 1.2237 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9653 - val_loss: 1.1824 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9653 - val_loss: 1.1824 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9586 - val_loss: 1.1517 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9586 - val_loss: 1.1517 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8933 - val_loss: 1.1490 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8933 - val_loss: 1.1490 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8447 - val_loss: 1.1456 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8447 - val_loss: 1.1456 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8322 - val_loss: 1.1316 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8322 - val_loss: 1.1316 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8724 - val_loss: 1.1183 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8724 - val_loss: 1.1183 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8210 - val_loss: 1.1811 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8210 - val_loss: 1.1811 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7872 - val_loss: 1.0892 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7872 - val_loss: 1.0892 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7797 - val_loss: 1.0688 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7797 - val_loss: 1.0688 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8277 - val_loss: 1.0787 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8277 - val_loss: 1.0787 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7988 - val_loss: 1.1095 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7988 - val_loss: 1.1095 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7596 - val_loss: 1.0877 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7596 - val_loss: 1.0877 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7769 - val_loss: 1.1065 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7769 - val_loss: 1.1065 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7606 - val_loss: 1.0406 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7606 - val_loss: 1.0406 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7657 - val_loss: 1.0529 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7657 - val_loss: 1.0529 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7774 - val_loss: 1.0840 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7774 - val_loss: 1.0840 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7272 - val_loss: 1.0389 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7272 - val_loss: 1.0389 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7283 - val_loss: 1.0627 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7283 - val_loss: 1.0627 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7684 - val_loss: 1.0260 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7684 - val_loss: 1.0260 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7192 - val_loss: 1.0126 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7192 - val_loss: 1.0126 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7528 - val_loss: 1.0094 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7528 - val_loss: 1.0094 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7281 - val_loss: 0.9989 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7281 - val_loss: 0.9989 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7039 - val_loss: 0.9373 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7039 - val_loss: 0.9373 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7218 - val_loss: 0.9828 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7218 - val_loss: 0.9828 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7072 - val_loss: 0.9366 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7072 - val_loss: 0.9366 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7061 - val_loss: 0.9482 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7061 - val_loss: 0.9482 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6871 - val_loss: 0.9725 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6871 - val_loss: 0.9725 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6635 - val_loss: 0.9180 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6635 - val_loss: 0.9180 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7004 - val_loss: 0.9567 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7004 - val_loss: 0.9567 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7006 - val_loss: 0.9186 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7006 - val_loss: 0.9186 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6915 - val_loss: 0.9177 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6915 - val_loss: 0.9177 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6721 - val_loss: 0.9164 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6721 - val_loss: 0.9164 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6771 - val_loss: 0.8877 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6771 - val_loss: 0.8877 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6839 - val_loss: 0.8930 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6839 - val_loss: 0.8930 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7229 - val_loss: 0.9180 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7229 - val_loss: 0.9180 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6685 - val_loss: 0.9072 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6685 - val_loss: 0.9072 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6438 - val_loss: 0.8656 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6438 - val_loss: 0.8656 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6638 - val_loss: 0.8622 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6638 - val_loss: 0.8622 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6608 - val_loss: 0.8896 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6608 - val_loss: 0.8896 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6831 - val_loss: 0.8836 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6831 - val_loss: 0.8836 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6494 - val_loss: 0.8593 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6494 - val_loss: 0.8593 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6706 - val_loss: 0.8513 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6706 - val_loss: 0.8513 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6365 - val_loss: 0.9104 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6365 - val_loss: 0.9104 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6908 - val_loss: 0.8668 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6908 - val_loss: 0.8668 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6800 - val_loss: 0.8631 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6800 - val_loss: 0.8631 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6237 - val_loss: 0.8759 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6237 - val_loss: 0.8759 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6465 - val_loss: 0.8650 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6465 - val_loss: 0.8650 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6686 - val_loss: 0.9117 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6686 - val_loss: 0.9117 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m15/31\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6067 \n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6267 - val_loss: 0.8615 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6267 - val_loss: 0.8615 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6080 - val_loss: 0.8379 - learning_rate: 5.0000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6080 - val_loss: 0.8379 - learning_rate: 5.0000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6555 - val_loss: 0.8694 - learning_rate: 5.0000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6555 - val_loss: 0.8694 - learning_rate: 5.0000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6309 - val_loss: 0.8474 - learning_rate: 5.0000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6309 - val_loss: 0.8474 - learning_rate: 5.0000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6548 - val_loss: 0.8611 - learning_rate: 5.0000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6548 - val_loss: 0.8611 - learning_rate: 5.0000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6706 - val_loss: 0.8543 - learning_rate: 5.0000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6706 - val_loss: 0.8543 - learning_rate: 5.0000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5967 - val_loss: 0.8612 - learning_rate: 5.0000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5967 - val_loss: 0.8612 - learning_rate: 5.0000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6404 - val_loss: 0.8467 - learning_rate: 5.0000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6404 - val_loss: 0.8467 - learning_rate: 5.0000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m17/31\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6675 \n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6537 - val_loss: 0.8411 - learning_rate: 5.0000e-04\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6537 - val_loss: 0.8411 - learning_rate: 5.0000e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6129 - val_loss: 0.8571 - learning_rate: 2.5000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6129 - val_loss: 0.8571 - learning_rate: 2.5000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6284 - val_loss: 0.8485 - learning_rate: 2.5000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6284 - val_loss: 0.8485 - learning_rate: 2.5000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6087 - val_loss: 0.8598 - learning_rate: 2.5000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6087 - val_loss: 0.8598 - learning_rate: 2.5000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6271 - val_loss: 0.8435 - learning_rate: 2.5000e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6271 - val_loss: 0.8435 - learning_rate: 2.5000e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6168 - val_loss: 0.8512 - learning_rate: 2.5000e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6168 - val_loss: 0.8512 - learning_rate: 2.5000e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6268 - val_loss: 0.8383 - learning_rate: 2.5000e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6268 - val_loss: 0.8383 - learning_rate: 2.5000e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m19/31\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5994 \n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6053 - val_loss: 0.8553 - learning_rate: 2.5000e-04\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6053 - val_loss: 0.8553 - learning_rate: 2.5000e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6054 - val_loss: 0.8501 - learning_rate: 1.2500e-04\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6054 - val_loss: 0.8501 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "model = build_lstm(input_shape=input_shape, units=32, loss='mae')\n",
    "\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    patience=15,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90874bd2",
   "metadata": {},
   "source": [
    "## Avaliação do Modelo\n",
    "\n",
    "Calcule MAE, RMSE e R² para o modelo LSTM simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c32dbadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Warning: 'feature_columns' from prepare_data_for_model is '['target_sum_next_4w', 'PIB', 'DENS', 'URB', 'CO2', 'CH4', 'N2O', 'LAT', 'LON', 'target_sum_next_4w']' and/or does not contain target 'target'. Assuming target is at index 0 for the scaler's features for denormalization.\n",
      "Métricas de Avaliação (escala original):\n",
      "MAE: 27.6212\n",
      "RMSE: 28.4157\n",
      "R²: -17.3736\n",
      "Warning: 'feature_columns' from prepare_data_for_model is '['target_sum_next_4w', 'PIB', 'DENS', 'URB', 'CO2', 'CH4', 'N2O', 'LAT', 'LON', 'target_sum_next_4w']' and/or does not contain target 'target'. Assuming target is at index 0 for the scaler's features for denormalization.\n",
      "Métricas de Avaliação (escala original):\n",
      "MAE: 27.6212\n",
      "RMSE: 28.4157\n",
      "R²: -17.3736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "# generate_forecasts is imported from src.train\n",
    "# scaler, y_test, X_test, model are from previous cells\n",
    "# target_column, feature_columns are defined in cell 9 from data_dict\n",
    "\n",
    "# Generate predictions (these are expected to be scaled)\n",
    "y_pred_scaled = generate_forecasts(model, X_test)\n",
    "\n",
    "# y_test is also scaled, from prepare_data_for_model.\n",
    "# Ensure y_test and y_pred_scaled are 2D for the scaler: (n_samples, n_features=1)\n",
    "y_test_for_scaler = np.asarray(y_test)\n",
    "y_pred_for_scaler = np.asarray(y_pred_scaled)\n",
    "\n",
    "if y_test_for_scaler.ndim == 1:\n",
    "    y_test_for_scaler = y_test_for_scaler.reshape(-1, 1)\n",
    "if y_pred_for_scaler.ndim == 1:\n",
    "    y_pred_for_scaler = y_pred_for_scaler.reshape(-1, 1)\n",
    "\n",
    "# Denormalize if scaler exists\n",
    "if scaler is not None:\n",
    "    # scaler.scale_ is the array of standard deviations. Its length is n_features_in_.\n",
    "    # For older sklearn versions, scaler.n_features_in_ might not exist, use len(scaler.scale_)\n",
    "    num_scaler_features = getattr(scaler, 'n_features_in_', len(scaler.scale_))\n",
    "\n",
    "    if num_scaler_features > 1 and y_test_for_scaler.shape[1] == 1:\n",
    "        # Scaler was fit on multiple features, but we have a single column (target) to denormalize.\n",
    "        # We need to find the index of our target_column in the features the scaler was fit on.\n",
    "        # 'target_column' (e.g., 'target') is from cell 9\n",
    "        # 'feature_columns' (list of column names scaler was fit on) is from data_dict in cell 9\n",
    "        \n",
    "        if feature_columns is None or target_column not in feature_columns:\n",
    "            # This is an issue. Defaulting to index 0 is a guess and might be wrong.\n",
    "            print(f\"Warning: 'feature_columns' from prepare_data_for_model is '{feature_columns}' and/or does not contain target '{target_column}'. Assuming target is at index 0 for the scaler's features for denormalization.\")\n",
    "            target_idx_in_scaler = 0\n",
    "            # Ensure the guessed index is valid if feature_columns was None but scaler has multiple features\n",
    "            if not (0 <= target_idx_in_scaler < num_scaler_features):\n",
    "                 raise ValueError(f\"Fallback target_idx {target_idx_in_scaler} is out of bounds for scaler with {num_scaler_features} features. Cannot denormalize.\")\n",
    "        else:\n",
    "            try:\n",
    "                target_idx_in_scaler = feature_columns.index(target_column)\n",
    "            except ValueError:\n",
    "                raise ValueError(f\"Target column '{target_column}' not found in scaler's feature_columns: {feature_columns}. Cannot determine correct parameters for denormalization.\")\n",
    "\n",
    "        # Ensure target_idx is within bounds for scaler.mean_ and scaler.scale_\n",
    "        if not (0 <= target_idx_in_scaler < num_scaler_features):\n",
    "            raise ValueError(f\"Determined target_idx {target_idx_in_scaler} is out of bounds for scaler with {num_scaler_features} features (mean/scale arrays length).\")\n",
    "            \n",
    "        target_mean = scaler.mean_[target_idx_in_scaler]\n",
    "        target_std = scaler.scale_[target_idx_in_scaler]\n",
    "\n",
    "        y_test_denorm = (y_test_for_scaler * target_std) + target_mean\n",
    "        y_pred_denorm = (y_pred_for_scaler * target_std) + target_mean\n",
    "    else:\n",
    "        # Scaler was fit on a single feature, or y_test_for_scaler has the same number of features.\n",
    "        # Direct inverse_transform should work.\n",
    "        y_test_denorm = scaler.inverse_transform(y_test_for_scaler)\n",
    "        y_pred_denorm = scaler.inverse_transform(y_pred_for_scaler)\n",
    "else:\n",
    "    y_test_denorm = y_test_for_scaler # Already in original scale if no scaler\n",
    "    y_pred_denorm = y_pred_for_scaler # Already in original scale if no scaler\n",
    "\n",
    "# Flatten to 1D for metrics and plotting\n",
    "y_test_1d = y_test_denorm.flatten()\n",
    "y_pred_1d = y_pred_denorm.flatten()\n",
    "\n",
    "# Calculate metrics on the original (denormalized) scale\n",
    "mae = mean_absolute_error(y_test_1d, y_pred_1d)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_1d, y_pred_1d))\n",
    "r2 = r2_score(y_test_1d, y_pred_1d)\n",
    "\n",
    "metrics = {\n",
    "    'mae': mae,\n",
    "    'rmse': rmse,\n",
    "    'r2': r2\n",
    "}\n",
    "\n",
    "print(\"Métricas de Avaliação (escala original):\")\n",
    "print(f\"MAE: {metrics['mae']:.4f}\")\n",
    "print(f\"RMSE: {metrics['rmse']:.4f}\")\n",
    "print(f\"R²: {metrics['r2']:.4f}\")\n",
    "\n",
    "# y_test_1d, y_pred_1d are now denormalized and 1D.\n",
    "# These will be used by the plotting cell and saving predictions cell.\n",
    "# test_df (for dates) and model_params (for horizon in titles) are also available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee1697f",
   "metadata": {},
   "source": [
    "## Visualização dos Resultados\n",
    "\n",
    "Plote os valores reais versus previstos e o erro de previsão. O alvo é a **soma das próximas 4 semanas** (previsão mensal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e57987f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (37,1) doesn't match the broadcast shape (37,10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m y_pred_1d \u001b[38;5;241m=\u001b[39m reduce_to_1d(generate_forecasts(model, X_test))\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 16\u001b[0m     y_test_1d \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_1d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     17\u001b[0m     y_pred_1d \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(y_pred_1d\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Align test_dates\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pedro\\OneDrive - Unesp\\Documentos\\GitHub\\treinamento_clusters_hpc\\.conda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1125\u001b[0m, in \u001b[0;36mStandardScaler.inverse_transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_std:\n\u001b[1;32m-> 1125\u001b[0m         X \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m   1126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n\u001b[0;32m   1127\u001b[0m         X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (37,1) doesn't match the broadcast shape (37,10)"
     ]
    }
   ],
   "source": [
    "# y_test_1d and y_pred_1d are already denormalized from the previous cell (Cell 13).\n",
    "# test_df is available from Cell 9 (ID: 26d32c4f)\n",
    "# model_params is available from Cell 9 (ID: 26d32c4f)\n",
    "\n",
    "# Align test_dates\n",
    "if 'week' in test_df.columns:\n",
    "    # y_test_1d is now the denormalized target series.\n",
    "    # test_df is the slice of the original dataframe for the test set.\n",
    "    # The dates should correspond to the time periods y_test_1d refers to.\n",
    "    test_dates = test_df['week'].values[-len(y_test_1d):]\n",
    "else:\n",
    "    test_dates = np.arange(len(y_test_1d))\n",
    "\n",
    "fig = plot_forecast(\n",
    "    true_values=y_test_1d,\n",
    "    predictions=y_pred_1d,\n",
    "    dates=test_dates,\n",
    "    title=f\"LSTM Simples: Previsão vs Real (Soma das próximas {model_params['forecast_horizon']} semanas)\",\n",
    "    true_label=f\"Real (soma {model_params['forecast_horizon']} sem)\",\n",
    "    pred_label=f\"Previsão LSTM (soma {model_params['forecast_horizon']} sem)\"\n",
    ")\n",
    "plt.savefig(os.path.join(results_dir, 'forecast_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "fig = plot_forecast_error(\n",
    "    true_values=y_test_1d,\n",
    "    predictions=y_pred_1d,\n",
    "    dates=test_dates,\n",
    "    title=f\"LSTM Simples: Erro de Previsão (Soma das próximas {model_params['forecast_horizon']} semanas)\"\n",
    ")\n",
    "plt.savefig(os.path.join(results_dir, 'error_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(test_df['week'], test_df['target'], label='Semanal Real', color='gray', alpha=0.5)\n",
    "plt.scatter(test_df['week'].values[-len(y_pred_1d):], y_pred_1d, label='Previsto (soma 4 semanas)', color='crimson', zorder=3)\n",
    "plt.scatter(test_df['week'].values[-len(y_test_1d):], y_test_1d, label='Real (soma 4 semanas)', color='royalblue', marker='x', zorder=3)\n",
    "plt.title('Série Semanal Real vs. Soma Prevista das 4 Semanas (Mensal)')\n",
    "plt.xlabel('Semana')\n",
    "plt.ylabel('Taxa de Morbidade Respiratória')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Diagnóstico: Verificar alinhamento de y_test e y_pred\n",
    "N = 10\n",
    "week_idx = test_dates  # Already aligned with y_test_1d and y_pred_1d\n",
    "df_diag = pd.DataFrame({\n",
    "    'week': week_idx[:N],\n",
    "    f'y_test (soma {model_params[\"forecast_horizon\"]} sem)': y_test_1d[:N],\n",
    "    f'y_pred (soma {model_params[\"forecast_horizon\"]} sem)': y_pred_1d[:N]\n",
    "})\n",
    "display(df_diag)\n",
    "\n",
    "# --- Advanced Evaluation and Visualization ---\n",
    "\n",
    "# 1. Forecast vs Actual (already present)\n",
    "fig1 = plot_forecast(y_test_1d, y_pred_1d, dates=test_dates, title=\"Forecast vs Actual\")\n",
    "fig1.show()\n",
    "\n",
    "# 2. Forecast Error (already present)\n",
    "fig2 = plot_forecast_error(y_test_1d, y_pred_1d, dates=test_dates, title=\"Forecast Error\")\n",
    "fig2.show()\n",
    "\n",
    "# 3. Distribution of Errors\n",
    "errors = y_pred_1d - y_test_1d\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(errors, kde=True, bins=30, color='crimson')\n",
    "plt.title('Distribution of Forecast Errors')\n",
    "plt.xlabel('Error (Predicted - Actual)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 4. Scatter Plot: Actual vs Predicted\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(y_test_1d, y_pred_1d, alpha=0.5)\n",
    "plt.plot([y_test_1d.min(), y_test_1d.max()], [y_test_1d.min(), y_test_1d.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Actual vs Predicted Scatter')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 5. Residuals Over Time\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(test_dates, errors, marker='o', linestyle='-', color='orange')\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "plt.title('Residuals Over Time')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Residual (Predicted - Actual)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 6. Rolling Mean of Errors\n",
    "window = 8\n",
    "rolling_error = pd.Series(errors).rolling(window=window).mean()\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(test_dates, rolling_error, color='purple')\n",
    "plt.title(f'Rolling Mean of Errors (window={window})')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Rolling Mean Error')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 7. Cumulative Error\n",
    "cumulative_error = np.cumsum(errors)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(test_dates, cumulative_error, color='teal')\n",
    "plt.title('Cumulative Forecast Error')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Cumulative Error')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 8. Feature Correlation Heatmap\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df_city.corr(), annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# 9. Target Distribution\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df_city['target'], kde=True, bins=30, color='royalblue')\n",
    "plt.title('Target Distribution')\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 10. Missing Values Heatmap\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.heatmap(df_city.isnull(), cbar=False, yticklabels=False)\n",
    "plt.title('Missing Values Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb7c032",
   "metadata": {},
   "source": [
    "## Salvar Resultados\n",
    "\n",
    "Salve as previsões e métricas para comparação posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb8ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save Results ---\n",
    "# Use correct city_name for saving\n",
    "city_name = str(CD_MUN_SELECTED) if CD_MUN_SELECTED is not None else 'all'\n",
    "preds_file = save_predictions(\n",
    "    y_true=y_test_1d,\n",
    "    y_pred=y_pred_1d,\n",
    "    dates=test_dates,\n",
    "    city_name=city_name,\n",
    "    model_name='lstm_simple',\n",
    "    output_dir=results_dir\n",
    ")\n",
    "print(f\"Previsões salvas em: {preds_file}\")\n",
    "\n",
    "metrics_file = save_metrics(\n",
    "    metrics=metrics,\n",
    "    city_name=city_name,\n",
    "    model_name='lstm_simple',\n",
    "    output_dir=results_dir,\n",
    "    params=model_params\n",
    ")\n",
    "print(f\"Métricas salvas em: {metrics_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d859876",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "O modelo LSTM simples serve como baseline neural para previsão de morbidade respiratória semanal. Compare seu desempenho com outros modelos nos próximos notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e586635",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
